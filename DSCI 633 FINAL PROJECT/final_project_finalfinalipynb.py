# -*- coding: utf-8 -*-
"""Final_Project_FINALFINALipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14mF2ZyhVbt-QaSGSfNcAy7DDzU43Tag7

STEVEN SZACHARA

DSCI633 FINAL PROJECT

LOADING UP THE DATASET INTO THE X AND y
"""

!pip install ucimlrepo
from ucimlrepo import fetch_ucirepo

# fetch dataset
diabetes_130_us_hospitals_for_years_1999_2008 = fetch_ucirepo(id=296)

# data (as pandas dataframes)
X = diabetes_130_us_hospitals_for_years_1999_2008.data.features
y = diabetes_130_us_hospitals_for_years_1999_2008.data.targets

"""After looking at the features and how they correlate using a random forest classifier in Final_Project_1, I determined the below columns to drop in order to not only speed up performance, but to eliminate the features that will skew the model

Also converted y to a binary classification
"""

##drop columns to improve performance and to eliminate noise
from sklearn.preprocessing import LabelEncoder
X = X.drop('weight', axis=1, errors='ignore')
columns_to_drop = [
    'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',
    'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',
    'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide',
    'examide', 'citoglipton', 'insulin', 'glyburide-metformin',
    'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone',
    'metformin-pioglitazone', 'payer_code', 'max_glu_serum', 'metformin', 'number_diagnoses'
]

# Drop the columns
X = X.drop(columns=columns_to_drop, axis=1, errors='ignore')

##convert y to binary, YES if <30, NO for any other
y_binary = ['NO' if (x == 'NO' or x == '>30') else 'YES' for x in y['readmitted']]
##then do 0 for all NOs, 1 for all YES(<30)
y = LabelEncoder().fit_transform(y_binary)

"""Eliminate any unknown gender, which I found to be only 3 entries, in the dataset from both X and y"""

# Assuming 'gender' is one of the columns in X
# Step 1: Filter out rows where gender is not 'Male' or 'Female'
valid_gender = X['gender'].isin(['Male', 'Female'])
# Step 2: Apply this filter to both X (features) and y (target)
X = X[valid_gender]
y = y[valid_gender]

"""Group the diagnosis columns into categories to streamline model performance, and to eliminate noise, drop the original columns and add the new columns into X"""

# Function to map ICD-9 codes to groups
def map_icd9_to_group(icd9_code):
    try:
        # Ensure the code is a string before splitting
        code_str = str(icd9_code)
        code = float(code_str.split('.')[0])  # Handle decimal codes
    except (ValueError, AttributeError):
        return 'Other'  # For codes that can't be converted to float

    if (250.000001 <= code <= 250.999999):
        return 'Diabetes'
    if (390 <= code <= 459) or code == 785:
        return 'Circulatory'
    if (460 <= code <= 519) or code == 786:
        return 'Respiratory'
    if (520 <= code <= 579) or code == 787:
        return 'Digestive'
    if (800 <= code <= 999):
        return 'Injury'
    if (710 <= code <= 739):
        return 'Musculoskeletal'
    if (580 <= code <= 629) or code == 788:
        return 'Genitourinary'
    if (140 <= code <= 239):
        return 'Neoplasms'
    return 'Other'

# Apply mapping to a diagnosis column
# Replace 'diag_1' with the correct column name in your dataset
if 'diag_1' in X.columns:  # Replace 'diag_1' with the ICD-9 column name in X
    X['D1'] = X['diag_1'].apply(map_icd9_to_group)
    X = X.drop(columns=['diag_1'])
if 'diag_2' in X.columns:  # Replace 'diag_2' with the ICD-9 column name in X
    X['D2'] = X['diag_2'].apply(map_icd9_to_group)
    X = X.drop(columns=['diag_2'])
if 'diag_3' in X.columns:  # Replace 'diag_3' with the ICD-9 column name in X
    X['D3'] = X['diag_3'].apply(map_icd9_to_group)
    X = X.drop(columns=['diag_3'])
else:
    print("Diagnosis column not found in dataset!")

# Check results
print(X.columns)

"""Checking to see if the gender has accurately been put into only 2 categories"""

value_counts = X['gender'].value_counts()
print("Value counts in the column:")
print(value_counts)

"""Checking to see if the diagnosis have been properly converted to new categories"""

value_counts = X['D1'].value_counts()
print("Value counts in the column:")
print(value_counts)
value_counts = X['D2'].value_counts()
print("Value counts in the column:")
print(value_counts)
value_counts = X['D3'].value_counts()
print("Value counts in the column:")
print(value_counts)

"""Checking admission type id to see what the status of that column is to be able to streamline the features better"""

value_counts = X['admission_type_id'].value_counts()
print("Value counts in the column:")
print(value_counts)

"""Below converts admission_type_id to just 2 categories"""

##emergency, urgent, or elective in admission ID, then other
def admission_type_(type_id):
    if (type_id == 1 or type_id == 2):
        return 1
    return 2

if 'admission_type_id' in X.columns:
    X['admission_typeID'] = X['admission_type_id'].apply(admission_type_)
    X = X.drop(columns=['admission_type_id'])
else:
    print("Diagnosis column not found in dataset!")
value_counts = X['admission_typeID'].value_counts()
print("Value counts in the column:")
print(value_counts)

"""Below removes the discharge dispositions rows in both X and y where the patients either die or sent to hospice

Then condense discharge disposition to either sending back home, or other, to streamline the model
"""

##remove discharge to hospice or death
valid_discharge = ~X['discharge_disposition_id'].isin([11, 13, 14, 19, 20, 21])
X = X[valid_discharge]
y = y[valid_discharge]
##then do discharge to home or otherwise
def discharge_disposition_(d_id):
    if (d_id == 1):
        return 1
    # Other
    return 2

if 'discharge_disposition_id' in X.columns:
    X['discharge_dispID'] = X['discharge_disposition_id'].apply(discharge_disposition_)
    X = X.drop(columns=['discharge_disposition_id'])
else:
    print("Diagnosis column not found in dataset!")
value_counts = X['discharge_dispID'].value_counts()
print("Value counts in the column:")
print(value_counts)

"""Below is to adjust the admission source to just 3 categories, emergency, referral, or otherwise"""

##admission source from emergency, referral, or otherwise
def admission_source_(s_id):
    if (s_id == 1 or s_id == 2):
        return 1
    if (s_id == 7):
        return 2
    # Add other group mappings here as needed
    return 3

if 'admission_source_id' in X.columns:  # Replace 'diag_1' with the ICD-9 column name in X
    X['admission_sourceID'] = X['admission_source_id'].apply(admission_source_)
    X = X.drop(columns=['admission_source_id'])
else:
    print("Diagnosis column not found in dataset!")
value_counts = X['admission_sourceID'].value_counts()
print("Value counts in the column:")
print(value_counts)

"""The below condenses the medical_specialty into just 6 categories instead of the long list below to eliminate noise and reduce model run-time"""

##speciality fixed down to 6
value_counts = X['medical_specialty'].value_counts()
print("Value counts in the column:")
print(value_counts)

import pandas as pd

# List of specialties
specialties = [
    'AllergyandImmunology', 'Anesthesiology', 'Anesthesiology-Pediatric', 'Cardiology', 'Cardiology-Pediatric', 'DCPTEAM',
    'Dentistry', 'Dermatology', 'Emergency/Trauma', 'Endocrinology', 'Endocrinology-Metabolism', 'Family/GeneralPractice',
    'Gastroenterology', 'Gynecology', 'Hematology', 'Hematology/Oncology', 'Hospitalist', 'InfectiousDiseases', 'InternalMedicine',
    'Nephrology', 'Neurology', 'Neurophysiology', 'Obsterics&Gynecology-GynecologicOnco', 'Obstetrics', 'ObstetricsandGynecology',
    'Oncology', 'Ophthalmology', 'Orthopedics', 'Orthopedics-Reconstructive', 'Osteopath', 'Otolaryngology', 'OutreachServices',
    'Pathology', 'Pediatrics', 'Pediatrics-AllergyandImmunology', 'Pediatrics-CriticalCare', 'Pediatrics-EmergencyMedicine',
    'Pediatrics-Endocrinology', 'Pediatrics-Hematology-Oncology', 'Pediatrics-InfectiousDiseases', 'Pediatrics-Neurology',
    'Pediatrics-Pulmonology', 'Perinatology', 'PhysicalMedicineandRehabilitation', 'PhysicianNotFound', 'Podiatry', 'Proctology',
    'Psychiatry', 'Psychiatry-Addictive', 'Psychiatry-Child/Adolescent', 'Psychology', 'Pulmonology', 'Radiologist', 'Radiology',
    'Resident', 'Rheumatology', 'Speech', 'SportsMedicine', 'Surgeon', 'Surgery-Cardiovascular', 'Surgery-Cardiovascular/Thoracic',
    'Surgery-Colon&Rectal', 'Surgery-General', 'Surgery-Maxillofacial', 'Surgery-Neuro', 'Surgery-Pediatric', 'Surgery-Plastic',
    'Surgery-PlasticwithinHeadandNeck', 'Surgery-Thoracic', 'Surgery-Vascular', 'SurgicalSpecialty', 'Urology'
]

# Define the mapping function
def classify_specialty(specialty):
    if specialty in ['AllergyandImmunology', 'Endocrinology', 'Endocrinology-Metabolism', 'Gastroenterology',
                     'Hematology', 'Hematology/Oncology', 'Hospitalist', 'InfectiousDiseases', 'InternalMedicine',
                     'Nephrology', 'Neurology', 'Oncology', 'Pulmonology', 'Rheumatology']:
        return 'Internal Medicine'
    elif specialty in ['Cardiology', 'Cardiology-Pediatric', 'Surgery-Cardiovascular', 'Surgery-Cardiovascular/Thoracic']:
        return 'Cardiology'
    elif specialty in ['Anesthesiology', 'Anesthesiology-Pediatric', 'Emergency/Trauma', 'ObstetricsandGynecology',
                       'Obstetrics', 'Orthopedics', 'Orthopedics-Reconstructive', 'Otolaryngology', 'Pathology',
                       'Surgery-General', 'Surgery-Maxillofacial', 'Surgery-Neuro', 'Surgery-Pediatric', 'Surgery-Plastic',
                       'Surgery-PlasticwithinHeadandNeck', 'Surgery-Thoracic', 'Surgery-Vascular', 'SurgicalSpecialty']:
        return 'Surgery'
    elif specialty in ['Family/GeneralPractice', 'Pediatrics', 'Pediatrics-AllergyandImmunology', 'Pediatrics-CriticalCare',
                       'Pediatrics-EmergencyMedicine', 'Pediatrics-Endocrinology', 'Pediatrics-Hematology-Oncology',
                       'Pediatrics-InfectiousDiseases', 'Pediatrics-Neurology', 'Pediatrics-Pulmonology', 'Perinatology',
                       'PhysicalMedicineandRehabilitation', 'SportsMedicine']:
        return 'Family/General Practice'
    elif specialty in ['DCPTEAM', 'PhysicianNotFound', 'OutreachServices']:
        return 'Missing or Unknown'
    else:
        return 'Other'

# Apply the classification
X['MedicalS'] = X['medical_specialty'].apply(classify_specialty)
X = X.drop(columns=['medical_specialty'])
value_counts = X['MedicalS'].value_counts()
print("Value counts in the column:")
print(value_counts)

"""Also reduced the race categories to speed up model and eliminate noise"""

##race reduced
value_counts = X['race'].value_counts()
print("Value counts in the column:")
print(value_counts)
# Map the 'race' column to the desired categories
X['race'] = X['race'].apply(lambda x: x if x in ['Caucasian', 'AfricanAmerican'] else 'Other')

# Check the result
print(X['race'].value_counts())

"""Also reduced age categoires to 3 categories"""

#age reduced to 3
value_counts = X['age'].value_counts()
print("Value counts in the column:")
print(value_counts)

# Define a function to categorize the age ranges
def categorize_age(age_range):
    if age_range in ['[0-10)', '[10-20)', '[20-30)']:  # Age 30 or younger
        return '30 or younger'
    elif age_range in ['[30-40)', '[40-50)', '[50-60)']:  # Age between 30 and 60
        return '30-60'
    elif age_range in ['[60-70)', '[70-80)', '[80-90)', '[90-100)']:  # Age 60 or older
        return '60+'
    return 'Other'

# Apply the function to the 'age' column
X['age'] = X['age'].apply(categorize_age)

# Check the updated value counts
print(X['age'].value_counts())

"""After performing feature engineering, split the data using stratify=y"""

# Split data into train and test sets with stratified sampling
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Check the class distribution to verify stratification
print("Training class distribution:", pd.Series(y_train).value_counts(normalize=True))
print("Test class distribution:", pd.Series(y_test).value_counts(normalize=True))

"""Below is the standard scaler and label encoder for every category in the dataset that is not already encoded or scaled"""

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import FunctionTransformer
import numpy as np


# Identify the categorical and numerical columns
categorical_cols = X_train.select_dtypes(include=['object']).columns
numerical_cols = X_train.select_dtypes(exclude=['object']).columns

# Create a function to apply label encoding
def label_encode_column(column):
    return LabelEncoder().fit_transform(column)

# Create preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),  # Apply scaling to numerical columns
        ('cat', FunctionTransformer(lambda x: np.apply_along_axis(label_encode_column, 0, x), validate=False), categorical_cols)  # Apply label encoding to categorical columns
    ])

# You can then fit and transform your data
X_train_preprocessed = preprocessor.fit_transform(X_train)
X_test_preprocessed = preprocessor.transform(X_test)

"""Apply SMOTE to the dataset, as the class distribution is way off, unfortunately this version of NearMiss and SMOTE performed worse"""

from imblearn.under_sampling import NearMiss
from imblearn.over_sampling import SMOTE

# Apply NearMiss to the majority class
near_miss = NearMiss(sampling_strategy='majority')
X_near_miss, y_near_miss = near_miss.fit_resample(X_train_preprocessed, y_train)

# Apply SMOTE to the minority class
smote = SMOTE(sampling_strategy='minority', random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_near_miss, y_near_miss)

"""BorderlineSMOTE seemed to work the best here"""

from imblearn.over_sampling import SMOTE
from imblearn.over_sampling import BorderlineSMOTE

# Apply SMOTE to training data
smote = BorderlineSMOTE(sampling_strategy='minority', random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train)

# Check new class distribution
from collections import Counter
print("Training class distribution after SMOTE:", Counter(y_train_resampled))

"""Applying PCA to the dataset"""

from sklearn.decomposition import PCA

# Step 3: Apply PCA to the preprocessed data
pca = PCA(n_components=15, svd_solver='randomized', random_state=42)  # You can adjust the number of components or variance threshold
X_train_pca = pca.fit_transform(X_train_resampled)
X_test_pca = pca.transform(X_test_preprocessed)

"""Applying PCA to the NearMiss, again not the right one, but just to test"""

from sklearn.decomposition import PCA

# Step 3: Apply PCA to the preprocessed data
pca = PCA(n_components=15, svd_solver='randomized', random_state=42)  # You can adjust the number of components or variance threshold
X_train_pca_resampled = pca.fit_transform(X_resampled)
X_test_pca_resampled = pca.transform(X_test_preprocessed)

"""Finally, the first model to use to train, Gaussian NB"""

# Initialize the Naive Bayes model (GaussianNB for continuous data)
from sklearn.naive_bayes import GaussianNB
model = GaussianNB()

# Train the model
model.fit(X_train_pca, y_train_resampled)

# Make predictions
y_pred = model.predict(X_test_pca)

# Evaluate the model
print("Accuracy Score: ", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Generate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Display confusion matrix
print("Confusion Matrix:")
print(cm)

"""AUC for Gaussian NB"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
# Get predicted probabilities (for class 1)
y_prob = model.predict_proba(X_test_pca)[:, 1]

# Compute ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob)

# Compute AUC
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='b', label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random model line (diagonal)
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

"""AdaboostClassifier model below:"""

# Import necessary libraries
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

# Step 2: Apply AdaBoost with the Decision Tree as the base learner
ada_boost = AdaBoostClassifier(n_estimators=50, random_state=42)

# Step 3: Fit AdaBoost model on the training data
ada_boost.fit(X_train_pca, y_train_resampled)

# Step 4: Make predictions
y_pred = ada_boost.predict(X_test_pca)

# Step 5: Evaluate the model
print("Accuracy Score: ", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
from sklearn.metrics import confusion_matrix
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""AUC for Adaboost"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
# Get predicted probabilities (for class 1)
y_prob = ada_boost.predict_proba(X_test_pca)[:, 1]

# Compute ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob)

# Compute AUC
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='b', label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random model line (diagonal)
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

"""Random Forest Classifier:"""

from sklearn.ensemble import RandomForestClassifier

# Initialize the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')  # You can tweak parameters

# Fit the model to training data
rf_model.fit(X_train_pca, y_train_resampled)

y_pred = rf_model.predict(X_test_pca)

# Evaluate model accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.4f}')

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:\n', conf_matrix)

# Classification Report (Precision, Recall, F1-score)
class_report = classification_report(y_test, y_pred)
print('Classification Report:\n', class_report)

"""AUC for Random Forest:"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
# Get predicted probabilities (for class 1)
y_prob = rf_model.predict_proba(X_test_pca)[:, 1]

# Compute ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob)

# Compute AUC
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='b', label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random model line (diagonal)
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

"""Xgboost model below:"""

!pip install xgboost
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Initialize XGBoost Classifier
xgb_model = xgb.XGBClassifier(
    objective='binary:logistic',  # Binary classification
    eval_metric='logloss',       # Evaluation metric for binary classification
    use_label_encoder=False,     # Avoid deprecated warnings
    random_state=42
)

# Train the model
xgb_model.fit(X_train_pca, y_train_resampled)

# Predict on the test set
y_pred = xgb_model.predict(X_test_pca)
y_pred_proba = xgb_model.predict_proba(X_test_pca)[:, 1]  # For ROC AUC

# Evaluate the model
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("\nROC AUC Score:")
print(roc_auc_score(y_test, y_pred_proba))

"""AUC for xgb model:"""

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
# Get predicted probabilities (for class 1)
y_prob = xgb_model.predict_proba(X_test_pca)[:, 1]

# Compute ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob)

# Compute AUC
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='b', label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random model line (diagonal)
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

"""GridSearchCV model:"""

##TAKES FOREVER

from sklearn.model_selection import GridSearchCV

# Parameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0],
}

# Grid Search
grid_search = GridSearchCV(
    estimator=xgb.XGBClassifier(random_state=42, use_label_encoder=False),
    param_grid=param_grid,
    scoring='roc_auc',
    cv=5,
    verbose=100,
    n_jobs=-1
)

grid_search.fit(X_train_pca, y_train_resampled)

# Best parameters and model
print("Best Parameters:", grid_search.best_params_)
best_model = grid_search.best_estimator_

"""Grid Search AUC:"""

from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# Predict on the test set
y_pred = best_model.predict(X_test_pca)
y_pred_proba = best_model.predict_proba(X_test_pca)[:, 1]  # Probabilities for the positive class

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Classification Report
report = classification_report(y_test, y_pred)
print("\nClassification Report:")
print(report)

# ROC AUC Score
roc_auc = roc_auc_score(y_test, y_pred_proba)
print("\nROC AUC Score:", roc_auc)

# Plot ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.2f})", color='blue')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random Guess')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend(loc="lower right")
plt.grid()
plt.show()